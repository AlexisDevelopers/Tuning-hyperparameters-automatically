{
  "cells": [
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "zqnYXBoMsbql"
      },
      "source": [
        "# Tuning hyperparameters automatically."
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "vgNimF5oshDO"
      },
      "source": [
        "Design of a Convolutional Neural Network (CNN) trained to classify the digits of the MNIST dataset using Keras Tuner to randomly explore the following hyperparameters.\n",
        "\n",
        "\n",
        "*   The network may have between 1 and 3 layer blocks (Conv2D+MaxPooling).\n",
        "*   The Conv2D layers may have filters of size 3, 5 or 7 to choose from.\n",
        "*   Conv2D layers may have a sigmoid or relu activation function.\n",
        "*   The Learning Rate is chosen from the list [0.5, 0.1, 0.05, 0.01, 005, 001.\n",
        "\n",
        "EarlyStopping is configured to watch if the val_acc worsens.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vPAe8Yc0RPd9",
        "outputId": "2483bb89-b79f-4db8-cd63-9451c735821d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m169.6/169.6 KB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m23.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "# Install the Keras Tuner package\n",
        "!pip install keras_tuner -q"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AA5J2g39R3a9"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import keras_tuner as kt\n",
        "from tensorflow                  import keras\n",
        "from tensorflow.keras.layers     import *\n",
        "from tensorflow.keras.optimizers import *\n",
        "from tensorflow.keras.utils      import to_categorical\n",
        "from tensorflow.keras            import Sequential\n",
        "from sklearn.model_selection     import train_test_split"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "upAiwGi3R4H_"
      },
      "outputs": [],
      "source": [
        "# We load the MNIST dataset\n",
        "mnist = np.genfromtxt('./sample_data/mnist_train_small.csv', delimiter=',')\n",
        "\n",
        "# Separate the labels from the images\n",
        "X = mnist[:, 1:]\n",
        "Y = mnist[:, 0:1]\n",
        "\n",
        "# We scale the data and One-Hot Encoding the output\n",
        "Xn = X / 255\n",
        "Yn = to_categorical(Y)\n",
        "\n",
        "# We use Sklearn's data splitter to train/test\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Partition train/test split to monitor overfitting\n",
        "X_train, X_test, Y_train, Y_test = train_test_split(Xn, Yn, test_size=0.3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9rEnJ0sgR4Fe"
      },
      "outputs": [],
      "source": [
        "# Organize the data in the form of tensors\n",
        "X_train = X_train.reshape(14000, 28, 28, 1)\n",
        "X_test = X_test.reshape(6000, 28, 28, 1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h53atnzlR4DK"
      },
      "outputs": [],
      "source": [
        "def build_model(hp):\n",
        "\n",
        "  # Create the model\n",
        "  model = Sequential()\n",
        "\n",
        "  # We create as many layers as decided in mlp_layers.\n",
        "  for i in range(hp.Int(\"Red_Neuronal_Convolucional\", 1, 3)):\n",
        "\n",
        "    # Create the first convolutional layer\n",
        "    model.add(Conv2D(filters=hp.Choice('filters', [3, 5, 7]), kernel_size=3, padding=\"same\", activation=hp.Choice('activation', [\"sigmoid\", \"relu\"]), input_shape=(28, 28, 1)))\n",
        "\n",
        "    # Add a layer of MaxPooling\n",
        "    model.add(MaxPooling2D())\n",
        "\n",
        "  # Convert the feature maps to vector\n",
        "  model.add(Flatten())\n",
        "\n",
        "  # We create the last layer with Dense connections\n",
        "  model.add(Dense(units=10, activation='softmax'))\n",
        "\n",
        "  # We can also use the Choice method to define a list of values to choose from automatically\n",
        "  model.compile(optimizer=Adam(learning_rate=hp.Choice('learning_rate', [0.5, 0.1, 0.05, 0.01, 0.005, 0.001])),\n",
        "                loss=\"mse\",\n",
        "                metrics=[\"acc\"])\n",
        "  \n",
        "  return model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zUCAaWvFR4A-",
        "outputId": "f3df25f3-38d0-4e66-bfa2-d6b14a82846f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d (Conv2D)             (None, 28, 28, 3)         30        \n",
            "                                                                 \n",
            " max_pooling2d (MaxPooling2D  (None, 14, 14, 3)        0         \n",
            " )                                                               \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 588)               0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 10)                5890      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 5,920\n",
            "Trainable params: 5,920\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "# We initialize the object that will contain the hyperparameters\n",
        "hp = kt.HyperParameters()\n",
        "\n",
        "# Let's check that the build_model method generates a model\n",
        "# of Keras functional and that everything is correct\n",
        "\n",
        "model = build_model(hp) # We generate the model\n",
        "model(X_train[:100])    # We initialize it with data. (necessary before making the summary)\n",
        "model.summary()         # We generate a summary of the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nMj28XHRR3-k",
        "outputId": "d71199f5-c9e1-4a26-cc30-5561b46cc1c8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Trial 100 Complete [00h 01m 24s]\n",
            "val_acc: 0.9330000281333923\n",
            "\n",
            "Best val_acc So Far: 0.9710000157356262\n",
            "Total elapsed time: 01h 52m 48s\n"
          ]
        }
      ],
      "source": [
        "# We configure Keras Tuner to\n",
        "# make 10 random searches\n",
        "# of the hyperparameter combination\n",
        "# that optimizes the validation accuracy\n",
        "\n",
        "tuner = kt.RandomSearch(\n",
        "    build_model,\n",
        "    max_trials=100,\n",
        "    overwrite=True,\n",
        "    objective=\"val_acc\",\n",
        "    directory=\"/tmp/tb\")\n",
        "\n",
        "# Once we have configured our \"fitter\"\n",
        "# random, we execute it with our data\n",
        "# of training. We use an\n",
        "# subset of total data to speed up\n",
        "# the training times in this phase.\n",
        "\n",
        "tuner.search(\n",
        "    X_train[:5000],\n",
        "    Y_train[:5000],\n",
        "    validation_split=0.2,\n",
        "    epochs=25,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ivIwkeQhR373",
        "outputId": "37b0f59c-c154-40ca-b508-9823249d7f3f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "438/438 [==============================] - 10s 21ms/step - loss: 0.0050 - acc: 0.9672 - val_loss: 0.0065 - val_acc: 0.9583\n",
            "Epoch 2/5\n",
            "438/438 [==============================] - 9s 20ms/step - loss: 0.0038 - acc: 0.9756 - val_loss: 0.0050 - val_acc: 0.9683\n",
            "Epoch 3/5\n",
            "438/438 [==============================] - 8s 18ms/step - loss: 0.0031 - acc: 0.9806 - val_loss: 0.0057 - val_acc: 0.9648\n",
            "Epoch 4/5\n",
            "438/438 [==============================] - 9s 21ms/step - loss: 0.0027 - acc: 0.9829 - val_loss: 0.0054 - val_acc: 0.9650\n",
            "Epoch 5/5\n",
            "438/438 [==============================] - 9s 21ms/step - loss: 0.0025 - acc: 0.9840 - val_loss: 0.0057 - val_acc: 0.9633\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fce35ce94c0>"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Once we have found the most optimal combination among all\n",
        "# the experiments carried out, now we can access the best\n",
        "# model all of them, and use it the same way as\n",
        "# we have previously worked with Keras.\n",
        "\n",
        "best_model = tuner.get_best_models()[0]\n",
        "best_model.fit(X_train, Y_train, validation_data=(X_test, Y_test), epochs=5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U1OB7u6KR31q",
        "outputId": "ef9ee1e7-7e6b-4570-b8d2-22f57cee72a1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d (Conv2D)             (None, 28, 28, 7)         70        \n",
            "                                                                 \n",
            " max_pooling2d (MaxPooling2D  (None, 14, 14, 7)        0         \n",
            " )                                                               \n",
            "                                                                 \n",
            " conv2d_1 (Conv2D)           (None, 14, 14, 7)         448       \n",
            "                                                                 \n",
            " max_pooling2d_1 (MaxPooling  (None, 7, 7, 7)          0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 343)               0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 10)                3440      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 3,958\n",
            "Trainable params: 3,958\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "{'Red_Neuronal_Convolucional': 2, 'filters': 7, 'activation': 'relu', 'learning_rate': 0.005}\n"
          ]
        }
      ],
      "source": [
        "# We print a detailed summary of the model with the hyperparameters tuned by Keras Tuner.\n",
        "print(best_model.summary())\n",
        "\n",
        "# We print the values of the hyperparameters selected as the best by Keras Tuner during the random hyperparameter search.\n",
        "print(tuner.get_best_hyperparameters()[0].values)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BmINFUQ6SKSL",
        "outputId": "6693fd5a-ac33-461e-af78-e05c5c80978c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "438/438 [==============================] - 11s 24ms/step - loss: 0.0019 - acc: 0.9901 - val_loss: 0.0054 - val_acc: 0.9722\n",
            "Epoch 2/100\n",
            "438/438 [==============================] - 11s 24ms/step - loss: 0.0022 - acc: 0.9885 - val_loss: 0.0058 - val_acc: 0.9702\n",
            "Epoch 3/100\n",
            "438/438 [==============================] - 10s 23ms/step - loss: 0.0017 - acc: 0.9908 - val_loss: 0.0063 - val_acc: 0.9673\n",
            "Epoch 4/100\n",
            "438/438 [==============================] - 10s 22ms/step - loss: 0.0014 - acc: 0.9924 - val_loss: 0.0057 - val_acc: 0.9700\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fce35ff1fd0>"
            ]
          },
          "execution_count": 24,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "\n",
        "# We configure the EarlyStopping\n",
        "early_stop = EarlyStopping(monitor=\"val_acc\", patience=3)\n",
        "\n",
        "# We train the model\n",
        "best_model.fit(X_train, Y_train, validation_data=(X_test, Y_test), \n",
        "               callbacks=[early_stop], epochs=100)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
